<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Real-Time VoiceüéôÔ∏è Translatorüîä | Samir Paul</title>
<meta name=keywords content="Real-Time Voice Translator,Coding blog,Computer Science"><meta name=description content="Real-Time Voice Translator"><meta name=author content="Samir Paul"><link rel=canonical href=https://samirpaulb.github.io/posts/real-time-voice-translator/><meta name=google-site-verification content="vJAOBxbJTCK2vXG-hLFeGsoC9hXgFlCpuJJ8AcJLROQ"><meta name=yandex-verification content="fe6a06c57be84984"><meta name=msvalidate.01 content="1A92FC2EC113F8616A21D76DA684A133"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://samirpaulb.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://samirpaulb.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://samirpaulb.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://samirpaulb.github.io/apple-touch-icon.png><link rel=mask-icon href=https://samirpaulb.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=manifest href=/manifest.json><link rel=sitemap type=application/xml title=Sitemap href=https://samirpaulb.github.io/sitemap.xml><link rel=alternate type=application/rss+xml title=RSS href=https://samirpaulb.github.io/index.xml><meta content="@SamirPaulb" name=twitter:site><meta content="@SamirPaulb" name=twitter:creator><meta content="24bac6e1fbf1750de40d59bb788d9dd9" name=p:domain_verify><meta content="6800281970014175" property="fb:app_id"><meta content="3pkgruuk3kzlsn3jdfehgbd4sem1qb" name=facebook-domain-verification><meta content="n93bHAYCJyRzj_9ccNNLKYUj03U0eWuhdV5Gb-bv2_g" name=google-site-verification><meta name=google-site-verification content="uziThFIJ1huzKLCKv-DChPbWZTRRFqmmdA6pcA-dqzs"><meta content="2xno70lnqo1ajcykeat10qud6lat0xlkc2bskxz0k9ma74g0bn-kprra5ev6bwui2s6-2394l0ryopjet7yt3hs8tokilug2cfhocw3r0nlj2t1xx690tgu82t59wtwi" name=norton-safeweb-site-verification><meta content="NHI3em00K1U3WmRGTTRHeWVGNUdNZz090" name=dmca-site-verification><link href=//fonts.googleapis.com rel='preconnect dns-prefetch'><link href=//storage.googleapis.com rel='preconnect dns-prefetch'><link href=//use.fontawesome.com rel='preconnect dns-prefetch'><link href=//ajax.googleapis.com rel='preconnect dns-prefetch'><link href=//ajax.microsoft.com rel='preconnect dns-prefetch'><link href=//github.com rel='preconnect dns-prefetch'><link href=//cdnjs.cloudflare.com rel='preconnect dns-prefetch'><link href=//www.google-analytics.com rel='preconnect dns-prefetch'><link href=//pagead2.googlesyndication.com rel='preconnect dns-prefetch'><link href=//googleads.g.doubleclick.net rel='preconnect dns-prefetch'><link href=//www.gstatic.com rel='preconnect dns-prefetch'><link href=//www.googletagmanager.com rel='preconnect dns-prefetch'><link href=//www.googletagservices.com rel='preconnect dns-prefetch'><link href=//static.xx.fbcdn.net rel='preconnect dns-prefetch'><link href=//tpc.googlesyndication.com rel='preconnect dns-prefetch'><link href=//apis.google.com rel='preconnect dns-prefetch'><link href=//www.w3.org rel='preconnect dns-prefetch'><link href=//www.facebook.com rel='preconnect dns-prefetch'><link href=//connect.facebook.net rel='preconnect dns-prefetch'><link href=//disqus.com rel='preconnect dns-prefetch'><link href=//samirpaul.disqus.com rel='preconnect dns-prefetch'><link href=//www.youtube.com rel='preconnect dns-prefetch'><link href=//img.youtube.com rel='preconnect dns-prefetch'><link href=//www.pinterest.com rel='preconnect dns-prefetch'><link href=//www.linkedin.com rel='preconnect dns-prefetch'><link href=//player.vimeo.com rel='preconnect dns-prefetch'><link href=//amazonaws.com rel='preconnect dns-prefetch'><link href=//s3.amazonaws.com rel='preconnect dns-prefetch'><link href=//s3.buysellads.com rel='preconnect dns-prefetch'><link href=//stats.buysellads.com rel='preconnect dns-prefetch'><link href=//scdn.netlify.app rel='preconnect dns-prefetch'><link href=//spcdn.pages.dev rel='preconnect dns-prefetch'><link href=//scdn.web.app rel='preconnect dns-prefetch'><link href=//user-images.githubusercontent.com rel='preconnect dns-prefetch'><link href=//raw.githubusercontent.com rel='preconnect dns-prefetch'><link href=//cdn.jsdelivr.net rel='preconnect dns-prefetch'><link href=//res.cloudinary.com rel='preconnect dns-prefetch'><link href=//cloudinary.com rel='preconnect dns-prefetch'><link href=//imgur.com rel='preconnect dns-prefetch'><link href=//i.imgur.com rel='preconnect dns-prefetch'><link href=//firebaseio.com rel='preconnect dns-prefetch'><link href=//translate.googleapis.com rel='preconnect dns-prefetch'><link href=//google.com rel='preconnect dns-prefetch'><link href=//analytics.google.com rel='preconnect dns-prefetch'><link href=//cse.google.com rel='preconnect dns-prefetch'><script async src="https://www.googletagmanager.com/gtag/js?id=G-CP4QE6ZEV0"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-CP4QE6ZEV0",{anonymize_ip:!1})}</script><meta property="og:title" content="Real-Time VoiceüéôÔ∏è Translatorüîä"><meta property="og:description" content="Real-Time Voice Translator"><meta property="og:type" content="article"><meta property="og:url" content="https://samirpaulb.github.io/posts/real-time-voice-translator/"><meta property="og:image" content="https://spcdn.pages.dev/real-time-voice-translator-og-image.webp"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-01-05T00:00:00+00:00"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/online-pdf-compression-tool/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/pyshooter/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/text-file-compressor-de-compressor-web-app/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/curated-list-of-project-based-tutorials/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://spcdn.pages.dev/real-time-voice-translator-og-image.webp"><meta name=twitter:title content="Real-Time VoiceüéôÔ∏è Translatorüîä"><meta name=twitter:description content="Real-Time Voice Translator"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog Posts","item":"https://samirpaulb.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Real-Time VoiceüéôÔ∏è Translatorüîä","item":"https://samirpaulb.github.io/posts/real-time-voice-translator/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Real-Time VoiceüéôÔ∏è Translatorüîä","name":"Real-Time VoiceüéôÔ∏è Translatorüîä","description":"Real-Time Voice Translator","keywords":["Real-Time Voice Translator","Coding blog","Computer Science"],"articleBody":"Repository Link: github.com/SamirPaulb/real-time-voice-translator\nAbstract Cross-lingual communication is a challenging task that requires accurate translation and natural and expressive speech. Existing solutions often rely on intermediate text representations, which introduce latency and lose the prosodic features of the original speech. In this paper, we present Real-Time Voice Translator, a machine learning project that aims to overcome these limitations by using deep neural networks to directly translate voice from one language to another in real-time. Our project is a desktop application that supports Windows, Linux, and Mac operating systems. It allows users to select the languages they want to translate between and start speaking. The application listens to the user‚Äôs voice and provides instant translations in real time while preserving the tone and emotion of the speaker. The application can also translate conversations between two or more people, enabling natural and fluent cross-lingual interactions. We evaluate our project on various metrics, such as translation quality, speech quality, latency, and user satisfaction. We demonstrate that our project achieves high performance and provides a seamless and natural experience of cross-lingual communication. We also discuss the future perspectives of our project, such as using voice cloning features to mimic the speaker‚Äôs voice in the target language and enhancing the emotional preservation of the translated speech. We believe that our project has the potential to revolutionize the field of cross-lingual communication and open new possibilities for cross-cultural exchange and collaboration.\nIndex Terms: Real-Time Voice Translation, Deep Learning, Voice Tone and Emotion Preservation, Desktop Application.\nIntroduction Imagine bridging language barriers in real time, preserving emotional nuances and fostering genuine cross-cultural understanding. Real-Time Voice Translator (RTVT) unlocks this possibility, utilizing deep learning to translate spoken words instantly, while faithfully mirroring the speaker‚Äôs tone and intent. This open-source, desktop application empowers seamless communication across languages, fostering empathy, collaboration, and a more connected world. This research unveils the technical backbone and transformative potential of RTVT, a tool poised to redefine how we interact and collaborate beyond linguistic borders.\nStudies and Findings The allure of instantaneous, seamless speech-to-speech translation across languages is undeniable. Research in end-to-end models like Google‚Äôs Translatotron, directly mapping speech spectrograms, offers a glimpse into this future. However, the realities of limited language compatibility and lingering technical hurdles made such an approach unsuitable for this real-time voice translator project.\nDrawing inspiration from established technologies, we embraced a hybrid approach, meticulously dissecting the translation process into speech-to-text, text-to-text translation, and finally, text-to-speech synthesis. This multi-step journey, while potentially a tad slower than its end-to-end counterparts, unlocked several key advantages. Firstly, it provided access to a vast pool of existing text translation models, vastly expanding the supported language pairs. Secondly, it paved the way for incorporating transliteration features, a valuable tool for bridging the gap between written and spoken forms of a language.\nThis decision wasn‚Äôt merely a practical compromise; it was a deliberate move towards a more robust and adaptable framework. While sacrificing the immediacy of spectrogram-based models, we gained a translation engine capable of tackling a wider range of languages and scenarios. As the field of speech-to-speech translation continues to evolve, this hybrid approach offers a stable platform for ongoing development, promising to bring the dream of real-time, cross-lingual communication ever closer to reality.\nSpeech Translation Model The Speech Translation Model (STM) orchestrates a series of interconnected processes to achieve real-time, cross-lingual voice communication. Here‚Äôs a breakdown of its core steps:\nVoice Input and Automatic Speech Recognition (ASR): The journey begins with capturing the user‚Äôs spoken utterance in the source language.\nASR technology meticulously analyzes the audio signal, mapping its acoustic features to linguistic units.\nThe intricate task of identifying phonemes, words, and their boundaries within continuous speech is performed with remarkable accuracy.\nInput Voice to Text Conversion: The ASR process culminates in a textual representation of the spoken input, ready for further linguistic transformations.\nThis stage ensures that the model has a structured foundation for subsequent translation and transliteration operations.\nTransliteration for Textual Adaptation: To bridge the gap between different writing systems and enhance translation accuracy, transliteration steps in.\nIt meticulously maps the characters of the source language text to their closest equivalents in the target language.\nThis process seamlessly adapts language-specific nuances, ensuring a smooth transition between written forms.\nTranslation of Transliterated Text: With the text carefully adapted for the target language, the translation engine takes centre stage.\nLeveraging sophisticated machine translation algorithms, it deciphers the meaning of the source text and artfully reconstructs it in the target language.\nThe model navigates the complexities of grammar, syntax, and semantics, striving for fluency and accuracy in the translated output.\nText-to-Speech Synthesis: The translated text now embarks on a journey back into the auditory realm.\nText-to-Speech (TTS) technology meticulously transforms written words into a natural-sounding speech signal.\nThis stage meticulously recreates the nuances of human intonation, rhythm, and pronunciation, breathing life into the translated message.\nVoice Output: The final step unveils the translated utterance in the target language, spoken aloud for the listener.\nThe model gracefully renders the translated text as intelligible speech, completing the cross-lingual communication loop.\nsolid foundation for subsequent translation.\ndeep-translator: This versatile library offers a comprehensive suite of translation capabilities, ensuring linguistic accuracy and fluency across a diverse range of language pairs.\ngoogle-transliteration-api: This API elegantly handled the task of transliteration, adapting text between different writing systems, fostering a seamless transition between languages.\ncx-Freeze: This tool enabled the packaging of the STM into standalone executable applications for Windows, Linux, and macOS, significantly broadening its accessibility and potential user base.\nProgram Flow: Voice Input: The journey begins with capturing the user‚Äôs spoken utterance in the source language, meticulously handled by pyaudio.\nAutomatic Speech Recognition: SpeechRecognition diligently analyzes the audio signal, converting it into text for further processing.\nTransliteration: The google-transliteration-api gracefully adapts the text to the target language‚Äôs writing system, ensuring optimal translation accuracy.\nTranslation: deep-translator leverages sophisticated translation algorithms to decipher the meaning of the source text and reconstruct it in the target language, preserving linguistic nuances.\nText-to-Speech Synthesis: gTTS meticulously transforms the translated text into a natural-sounding speech signal, breathing life into the translated message.\nVoice Output: playsound delivers the translated utterance in the target language, completing the cross-lingual communication loop.\nInstallation and Usage Dependencies \u003c=Python3.11, gTTS, pyaudio, playsound==1.2.2, deep-translator, SpeechRecognition, google-transliteration-api, cx-Freeze Getting started Clone this project and create virtualenv (recommended) and activate virtualenv.\n1 2 3 4 5 6 7 8 # Create virtualenv python -m venv env # Linux/MacOS source env/bin/activate # Windows env\\Scripts\\activate Install require dependencies.\n1 2 3 pip install --upgrade wheel pip install -r requirements.txt Run code and speech (have fun).\n1 python main.py Install Windows/Linux/Mac Application I am using cx_Freeze to build executable file of this app. The build settings can be changed by modifying the setup.py file.\nBuild installer containing all the files: Windows: python setup.py bdist_msi Linux: python setup.py bdist_rpm Mac: python setup.py bdist_mac GUI Conclusion Real-Time Voice Translator shatters language barriers with its deep learning-powered hybrid approach. Beyond accurate translations, it captures the essence of human speech, fostering genuine cross-cultural understanding. This research unveils its robust framework, adaptable design, and potential for future advancements like voice cloning and emotion preservation. Real-Time Voice Translator intuitive interface and cross-platform compatibility empower diverse users to navigate the world with ease. More than just a tool, it‚Äôs a bridge of empathy and collaboration, one voice at a time. By embracing Real-Time Voice Translator, we step closer to a world where communication transcends borders, uniting cultures and shaping a more connected future.\nFuture Work While this project currently delivers impressive real-time translations, the future holds even greater potential for capturing the full spectrum of human communication. Sentiment and emotion analysis models like EmoNet and SyntaxNet offer exciting possibilities for preserving the speaker‚Äôs intended meaning beyond mere words. Integrating these tools could allow Real-Time Voice Translator to translate expressions of joy, anger, or sarcasm with nuanced accuracy, fostering deeper cross-cultural understanding.\nOpen-source toolkits like PaddleSpeech and espnet, known for their advanced speech-processing capabilities, could further enhance the translation process. Their deep learning frameworks offer the potential for improvements in speech recognition, natural language understanding, and text-to-speech synthesis. Additionally, incorporating SoftVC VITS Singing Voice Conversion technology could unlock fascinating avenues for translating emotional melodies and vocal inflections, adding a truly human touch to translated speech.\nWe‚Äôre actively exploring the integration of OpenAI‚Äôs Whisper ASR model, renowned for its speech recognition accuracy, and ElevenLabs‚Äô natural-sounding speech APIs. These advancements promise to elevate the user experience, delivering translated speech that seamlessly captures the speaker‚Äôs original voice quality and emotional tone. Finally, accent softening models like Tomato.ai could be implemented to reduce speaker-specific characteristics in the translated speech, ensuring clearer and more universal comprehension.\nBy embracing these cutting-edge technologies and pursuing continuous research, Real-Time Voice Translator aims to transcend the limitations of traditional translation. Our vision is to create a tool that not only bridges languages but also bridges hearts, fostering a world where emotions and intentions resonate across all barriers.\nReferences Cambria, Erik, and Jamin Shi. ‚ÄúSemantic sentiment analysis.‚Äù IEEE Transactions on Affective Computing 7.4 (2015): 266-279.\nSocher, Richard, et al. ‚ÄúRecursive deep learning for sentiment analysis.‚Äù Proceedings of the 28th International Conference on Machine Learning. ACM, 2013.\nPaddlePaddle Team. paddlepaddle speech recognition ON PaddlePaddle paddlepaddle.org.cn.\nESPNet Working Group. ‚ÄúESPnet.‚Äù GitHub Pages, github.com.\nHsu, Wei-Ning, et al. ‚ÄúSoftVC: High-fidelity TTS with Mel-Style Transfer.‚Äù arXiv preprint arXiv:2301.04765 (2023).\nOpenAI Whisper: Open-Source Speech Recognition.\nElevenLabs. ‚ÄúElevenLabs.‚Äù eleventlabs.io.\nTomato.ai. ‚ÄúTomato.ai‚Äù.\nMohri, Mehryar, et al. ‚ÄúFoundations of machine learning.‚Äù MIT press, 2018.\nThis post is licensed under a Creative Commons Attribution 4.0 International License. Distribution and adaptation are permitted under the terms of the license, with appropriate attribution required. All rights not expressly granted are reserved. For further information, please visit dmca.com/r/jkzgz6y.\n","wordCount":"1616","inLanguage":"en","image":"https://spcdn.pages.dev/real-time-voice-translator-og-image.webp","datePublished":"2024-01-05T00:00:00Z","dateModified":"2024-01-05T00:00:00Z","author":[{"@type":"Person","name":"Samir Paul"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://samirpaulb.github.io/posts/real-time-voice-translator/"},"publisher":{"@type":"Organization","name":"Samir Paul","logo":{"@type":"ImageObject","url":"https://samirpaulb.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://samirpaulb.github.io/ accesskey=h title="Samir Paul (Alt + H)">Samir Paul</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://samirpaulb.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://samirpaulb.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://samirpaulb.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://samirpaulb.github.io/>Home</a>&nbsp;¬ª&nbsp;<a href=https://samirpaulb.github.io/posts/>Blog Posts</a></div><h1 class="post-title entry-hint-parent">Real-Time VoiceüéôÔ∏è Translatorüîä</h1><div class=post-meta><span title='2024-01-05 00:00:00 +0000 UTC'>January 5, 2024</span>&nbsp;¬∑&nbsp;8 min&nbsp;¬∑&nbsp;1616 words&nbsp;¬∑&nbsp;Samir Paul</div></header><figure class=entry-cover><img loading=eager src=https://spcdn.pages.dev/real-time-voice-translator-og-image.webp alt="Real-Time Voice Translator"></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#abstract aria-label=Abstract>Abstract</a></li><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#studies-and-findings aria-label="Studies and Findings">Studies and Findings</a></li><li><a href=#speech-translation-model aria-label="Speech Translation Model">Speech Translation Model</a></li><li><a href=#installation-and-usage aria-label="Installation and Usage">Installation and Usage</a><ul><li><a href=#dependencies aria-label=Dependencies>Dependencies</a></li><li><a href=#getting-started aria-label="Getting started">Getting started</a></li><li><a href=#install-windowslinuxmac-application aria-label="Install Windows/Linux/Mac Application">Install Windows/Linux/Mac Application</a><ul><ul><li><a href=#build-installer-containing-all-the-files aria-label="Build installer containing all the files:">Build installer containing all the files:</a></li></ul></ul></li><li><a href=#gui aria-label=GUI>GUI</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#future-work aria-label="Future Work">Future Work</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p><b>Repository Link: <a href=https://github.com/SamirPaulb/real-time-voice-translator>github.com/SamirPaulb/real-time-voice-translator</a></b></p><h2 id=abstract>Abstract<a hidden class=anchor aria-hidden=true href=#abstract>#</a></h2><p><em>Cross-lingual communication is a challenging task that requires accurate translation and natural and expressive speech. Existing solutions often rely on intermediate text representations, which introduce latency and lose the prosodic features of the original speech. In this paper, we present Real-Time Voice Translator, a machine learning project that aims to overcome these limitations by using deep neural networks to directly translate voice from one language to another in real-time. Our project is a desktop application that supports Windows, Linux, and Mac operating systems. It allows users to select the languages they want to translate between and start speaking. The application listens to the user&rsquo;s voice and provides instant translations in real time while preserving the tone and emotion of the speaker. The application can also translate conversations between two or more people, enabling natural and fluent cross-lingual interactions. We evaluate our project on various metrics, such as translation quality, speech quality, latency, and user satisfaction. We demonstrate that our project achieves high performance and provides a seamless and natural experience of cross-lingual communication. We also discuss the future perspectives of our project, such as using voice cloning features to mimic the speaker&rsquo;s voice in the target language and enhancing the emotional preservation of the translated speech. We believe that our project has the potential to revolutionize the field of cross-lingual communication and open new possibilities for cross-cultural exchange and collaboration.</em></p><p><strong>Index Terms</strong>: <code>Real-Time Voice Translation</code>, <code>Deep Learning</code>, <code>Voice Tone and Emotion Preservation</code>, <code>Desktop Application</code>.</p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Imagine bridging language barriers in real time, preserving emotional nuances and fostering genuine cross-cultural understanding. Real-Time Voice Translator (RTVT) unlocks this possibility, utilizing deep learning to translate spoken words instantly, while faithfully mirroring the speaker&rsquo;s tone and intent. This open-source, desktop application empowers seamless communication across languages, fostering empathy, collaboration, and a more connected world. This research unveils the technical backbone and transformative potential of RTVT, a tool poised to redefine how we interact and collaborate beyond linguistic borders.</p><h2 id=studies-and-findings>Studies and Findings<a hidden class=anchor aria-hidden=true href=#studies-and-findings>#</a></h2><p>The allure of instantaneous, seamless speech-to-speech translation across languages is undeniable. Research in end-to-end models like Google&rsquo;s Translatotron, directly mapping speech spectrograms, offers a glimpse into this future. However, the realities of limited language compatibility and lingering technical hurdles made such an approach unsuitable for this real-time voice translator project.</p><p>Drawing inspiration from established technologies, we embraced a hybrid approach, meticulously dissecting the translation process into speech-to-text, text-to-text translation, and finally, text-to-speech synthesis. This multi-step journey, while potentially a tad slower than its end-to-end counterparts, unlocked several key advantages. Firstly, it provided access to a vast pool of existing text translation models, vastly expanding the supported language pairs. Secondly, it paved the way for incorporating transliteration features, a valuable tool for bridging the gap between written and spoken forms of a language.</p><p>This decision wasn&rsquo;t merely a practical compromise; it was a deliberate move towards a more robust and adaptable framework. While sacrificing the immediacy of spectrogram-based models, we gained a translation engine capable of tackling a wider range of languages and scenarios. As the field of speech-to-speech translation continues to evolve, this hybrid approach offers a stable platform for ongoing development, promising to bring the dream of real-time, cross-lingual communication ever closer to reality.</p><h2 id=speech-translation-model>Speech Translation Model<a hidden class=anchor aria-hidden=true href=#speech-translation-model>#</a></h2><p>The Speech Translation Model (STM) orchestrates a series of interconnected processes to achieve real-time, cross-lingual voice communication. Here&rsquo;s a breakdown of its core steps:</p><ol><li><strong>Voice Input and Automatic Speech Recognition (ASR)</strong>:</li></ol><ul><li><p>The journey begins with capturing the user&rsquo;s spoken utterance in the source language.</p></li><li><p>ASR technology meticulously analyzes the audio signal, mapping its acoustic features to linguistic units.</p></li><li><p>The intricate task of identifying phonemes, words, and their boundaries within continuous speech is performed with remarkable accuracy.</p></li></ul><ol start=2><li><strong>Input Voice to Text Conversion</strong>:</li></ol><ul><li><p>The ASR process culminates in a textual representation of the spoken input, ready for further linguistic transformations.</p></li><li><p>This stage ensures that the model has a structured foundation for subsequent translation and transliteration operations.</p></li></ul><ol start=3><li><strong>Transliteration for Textual Adaptation</strong>:</li></ol><ul><li><p>To bridge the gap between different writing systems and enhance translation accuracy, transliteration steps in.</p></li><li><p>It meticulously maps the characters of the source language text to their closest equivalents in the target language.</p></li><li><p>This process seamlessly adapts language-specific nuances, ensuring a smooth transition between written forms.</p></li></ul><ol start=4><li><strong>Translation of Transliterated Text</strong>:</li></ol><ul><li><p>With the text carefully adapted for the target language, the translation engine takes centre stage.</p></li><li><p>Leveraging sophisticated machine translation algorithms, it deciphers the meaning of the source text and artfully reconstructs it in the target language.</p></li><li><p>The model navigates the complexities of grammar, syntax, and semantics, striving for fluency and accuracy in the translated output.</p></li></ul><ol start=5><li><strong>Text-to-Speech Synthesis</strong>:</li></ol><ul><li><p>The translated text now embarks on a journey back into the auditory realm.</p></li><li><p>Text-to-Speech (TTS) technology meticulously transforms written words into a natural-sounding speech signal.</p></li><li><p>This stage meticulously recreates the nuances of human intonation, rhythm, and pronunciation, breathing life into the translated message.</p></li></ul><ol start=6><li><strong>Voice Output</strong>:</li></ol><ul><li><p>The final step unveils the translated utterance in the target language, spoken aloud for the listener.</p></li><li><p>The model gracefully renders the translated text as intelligible speech, completing the cross-lingual communication loop.</p></li><li><p>solid foundation for subsequent translation.</p></li><li><p>deep-translator: This versatile library offers a comprehensive suite of translation capabilities, ensuring linguistic accuracy and fluency across a diverse range of language pairs.</p></li><li><p>google-transliteration-api: This API elegantly handled the task of transliteration, adapting text between different writing systems, fostering a seamless transition between languages.</p></li><li><p>cx-Freeze: This tool enabled the packaging of the STM into standalone executable applications for Windows, Linux, and macOS, significantly broadening its accessibility and potential user base.</p></li></ul><p><strong>Program Flow:</strong>
<img loading=lazy src=https://github.com/SamirPaulb/real-time-voice-translator/assets/77569653/73dd62d6-798d-4129-aff3-16d6d932a817 alt="Program Flow"></p><ul><li><p><strong>Voice Input</strong>: The journey begins with capturing the user&rsquo;s spoken utterance in the source language, meticulously handled by pyaudio.</p></li><li><p><strong>Automatic Speech Recognition</strong>: SpeechRecognition diligently analyzes the audio signal, converting it into text for further processing.</p></li><li><p><strong>Transliteration</strong>: The google-transliteration-api gracefully adapts the text to the target language&rsquo;s writing system, ensuring optimal translation accuracy.</p></li><li><p><strong>Translation</strong>: deep-translator leverages sophisticated translation algorithms to decipher the meaning of the source text and reconstruct it in the target language, preserving linguistic nuances.</p></li><li><p><strong>Text-to-Speech Synthesis</strong>: gTTS meticulously transforms the translated text into a natural-sounding speech signal, breathing life into the translated message.</p></li><li><p><strong>Voice Output</strong>: playsound delivers the translated utterance in the target language, completing the cross-lingual communication loop.</p></li></ul><h2 id=installation-and-usage>Installation and Usage<a hidden class=anchor aria-hidden=true href=#installation-and-usage>#</a></h2><h3 id=dependencies>Dependencies<a hidden class=anchor aria-hidden=true href=#dependencies>#</a></h3><pre><code>&lt;=Python3.11, gTTS, pyaudio, playsound==1.2.2, deep-translator, SpeechRecognition, google-transliteration-api, cx-Freeze
</code></pre><h3 id=getting-started>Getting started<a hidden class=anchor aria-hidden=true href=#getting-started>#</a></h3><ol><li><p>Clone <a href=https://github.com/SamirPaulb/real-time-voice-translator>this project</a> and create virtualenv (recommended) and activate virtualenv.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1>1</a>
</span><span class=lnt id=hl-0-2><a class=lnlinks href=#hl-0-2>2</a>
</span><span class=lnt id=hl-0-3><a class=lnlinks href=#hl-0-3>3</a>
</span><span class=lnt id=hl-0-4><a class=lnlinks href=#hl-0-4>4</a>
</span><span class=lnt id=hl-0-5><a class=lnlinks href=#hl-0-5>5</a>
</span><span class=lnt id=hl-0-6><a class=lnlinks href=#hl-0-6>6</a>
</span><span class=lnt id=hl-0-7><a class=lnlinks href=#hl-0-7>7</a>
</span><span class=lnt id=hl-0-8><a class=lnlinks href=#hl-0-8>8</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># Create virtualenv
</span></span><span class=line><span class=cl>python -m venv env
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Linux/MacOS
</span></span><span class=line><span class=cl>source env/bin/activate
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Windows
</span></span><span class=line><span class=cl>env\Scripts\activate
</span></span></code></pre></td></tr></table></div></div></li><li><p>Install require dependencies.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1>1</a>
</span><span class=lnt id=hl-1-2><a class=lnlinks href=#hl-1-2>2</a>
</span><span class=lnt id=hl-1-3><a class=lnlinks href=#hl-1-3>3</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>pip install --upgrade wheel
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>pip install -r requirements.txt
</span></span></code></pre></td></tr></table></div></div></li><li><p>Run code and speech (have fun).</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a class=lnlinks href=#hl-2-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>python main.py
</span></span></code></pre></td></tr></table></div></div></li></ol><h3 id=install-windowslinuxmac-application>Install Windows/Linux/Mac Application<a hidden class=anchor aria-hidden=true href=#install-windowslinuxmac-application>#</a></h3><p><a href=https://github.com/SamirPaulb/real-time-voice-translator/releases/latest><img src=https://user-images.githubusercontent.com/132539454/278971282-8d676023-a03a-463c-8e55-3f0afe6e3e58.svg alt=DOWNLOAD></a></p><p>I am using <a href=https://github.com/marcelotduarte/cx_Freeze/tree/main>cx_Freeze</a> to build executable file of this app. The build settings can be changed by modifying the <a href=https://github.com/SamirPaulb/real-time-voice-translator/blob/main/setup.py>setup.py</a> file.</p><h5 id=build-installer-containing-all-the-files>Build installer containing all the files:<a hidden class=anchor aria-hidden=true href=#build-installer-containing-all-the-files>#</a></h5><ul><li>Windows: <code>python setup.py bdist_msi</code></li><li>Linux: <code>python setup.py bdist_rpm</code></li><li>Mac: <code>python setup.py bdist_mac</code></li></ul><h3 id=gui>GUI<a hidden class=anchor aria-hidden=true href=#gui>#</a></h3><p><a href=#><img src=https://github.com/SamirPaulb/real-time-voice-translator/assets/77569653/f96a4115-a88f-4096-9a00-954b8527d872 alt="App GUI"></a></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Real-Time Voice Translator shatters language barriers with its deep learning-powered hybrid approach. Beyond accurate translations, it captures the essence of human speech, fostering genuine cross-cultural understanding. This research unveils its robust framework, adaptable design, and potential for future advancements like voice cloning and emotion preservation. Real-Time Voice Translator intuitive interface and cross-platform compatibility empower diverse users to navigate the world with ease. More than just a tool, it&rsquo;s a bridge of empathy and collaboration, one voice at a time. By embracing Real-Time Voice Translator, we step closer to a world where communication transcends borders, uniting cultures and shaping a more connected future.</p><h2 id=future-work>Future Work<a hidden class=anchor aria-hidden=true href=#future-work>#</a></h2><p>While this project currently delivers impressive real-time translations, the future holds even greater potential for capturing the full spectrum of human communication. Sentiment and emotion analysis models like EmoNet and SyntaxNet offer exciting possibilities for preserving the speaker&rsquo;s intended meaning beyond mere words. Integrating these tools could allow Real-Time Voice Translator to translate expressions of joy, anger, or sarcasm with nuanced accuracy, fostering deeper cross-cultural understanding.</p><p>Open-source toolkits like PaddleSpeech and espnet, known for their advanced speech-processing capabilities, could further enhance the translation process. Their deep learning frameworks offer the potential for improvements in speech recognition, natural language understanding, and text-to-speech synthesis. Additionally, incorporating SoftVC VITS Singing Voice Conversion technology could unlock fascinating avenues for translating emotional melodies and vocal inflections, adding a truly human touch to translated speech.</p><p>We&rsquo;re actively exploring the integration of OpenAI&rsquo;s Whisper ASR model, renowned for its speech recognition accuracy, and ElevenLabs&rsquo; natural-sounding speech APIs. These advancements promise to elevate the user experience, delivering translated speech that seamlessly captures the speaker&rsquo;s original voice quality and emotional tone. Finally, accent softening models like Tomato.ai could be implemented to reduce speaker-specific characteristics in the translated speech, ensuring clearer and more universal comprehension.</p><p>By embracing these cutting-edge technologies and pursuing continuous research, Real-Time Voice Translator aims to transcend the limitations of traditional translation. Our vision is to create a tool that not only bridges languages but also bridges hearts, fostering a world where emotions and intentions resonate across all barriers.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li><p>Cambria, Erik, and Jamin Shi. &ldquo;Semantic sentiment analysis.&rdquo; IEEE Transactions on Affective Computing 7.4 (2015): 266-279.</p></li><li><p>Socher, Richard, et al. &ldquo;Recursive deep learning for sentiment analysis.&rdquo; Proceedings of the 28th International Conference on Machine Learning. ACM, 2013.</p></li><li><p><a href=https://github.com/PaddlePaddle/PaddleSpeech>PaddlePaddle Team</a>. paddlepaddle speech recognition ON PaddlePaddle paddlepaddle.org.cn.</p></li><li><p>ESPNet Working Group. &ldquo;ESPnet.&rdquo; GitHub Pages, github.com.</p></li><li><p>Hsu, Wei-Ning, et al. &ldquo;SoftVC: High-fidelity TTS with Mel-Style Transfer.&rdquo; arXiv preprint arXiv:2301.04765 (2023).</p></li><li><p>OpenAI <a href=https://github.com/openai/whisper>Whisper</a>: Open-Source Speech Recognition.</p></li><li><p>ElevenLabs. &ldquo;ElevenLabs.&rdquo; eleventlabs.io.</p></li><li><p>Tomato.ai. &ldquo;Tomato.ai&rdquo;.</p></li><li><p>Mohri, Mehryar, et al. &ldquo;Foundations of machine learning.&rdquo; MIT press, 2018.</p></li></ol><hr><p>This post is licensed under a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>. Distribution and adaptation are permitted under the terms of the license, with appropriate attribution required. All rights not expressly granted are reserved. For further information, please visit <a href=https://www.dmca.com/r/jkzgz6y>dmca.com/r/jkzgz6y</a>.</p><p><a href=https://www.dmca.com/r/jkzgz6y><img loading=lazy src=https://www.dmca.com/Badges/dmca-badge-w250-5x1-06.png alt="DMCA.com Protection Status"></a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://samirpaulb.github.io/tags/python/>python</a></li><li><a href=https://samirpaulb.github.io/tags/voice-translator/>voice-translator</a></li><li><a href=https://samirpaulb.github.io/tags/research-paper/>research-paper</a></li></ul><nav class=paginav><a class=next href=https://samirpaulb.github.io/posts/data-structures-and-algorithms-for-coding-interview/><span class=title>Next ¬ª</span><br><span>Data Structures and Algorithms for Coding Interview</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on x" href="https://x.com/intent/tweet/?text=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a&amp;url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f&amp;hashtags=python%2cvoice-translator%2cresearch-paper"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f&amp;title=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a&amp;summary=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a&amp;source=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f&title=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on whatsapp" href="https://api.whatsapp.com/send?text=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a%20-%20https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on telegram" href="https://telegram.me/share/url?text=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a&amp;url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Real-Time VoiceüéôÔ∏è Translatorüîä on ycombinator" href="https://news.ycombinator.com/submitlink?t=Real-Time%20Voice%f0%9f%8e%99%ef%b8%8f%20Translator%f0%9f%94%8a&u=https%3a%2f%2fsamirpaulb.github.io%2fposts%2freal-time-voice-translator%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://samirpaulb.github.io/>Samir Paul</a></span>
<span>‚Ä¢ <a href=/sitemap.xml>Sitemap</a> ‚Ä¢ <a href=/privacy>Privacy</a> ‚Ä¢ <a href=/disclaimer>Disclaimer</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script defer loading=lazy>window.addEventListener("DOMContentLoaded",function(){for(var n=document.getElementsByTagName("a"),t=0;t<n.length;t++)n[t].hostname!==window.location.hostname&&(n[t].setAttribute("target","_blank"),n[t].setAttribute("rel","noopener"))})</script><script defer loading=lazy>if("serviceWorker"in navigator){const e=!0,t=["index","next","prev","prefetch"];function prefetchCache(){if(navigator.serviceWorker.controller){let e=document.querySelectorAll(t.map(e=>"link[rel="+e+"]").join(","));e.length>0&&Array.from(e).map(e=>{let t=e.getAttribute("href");navigator.serviceWorker.controller.postMessage({action:"cache",url:t})})}}navigator.serviceWorker.register("/sw.js",{scope:"/"}).then(()=>{console.log("Service Worker Registered")}),navigator.serviceWorker.ready.then(()=>{e&&prefetchCache()})}</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>